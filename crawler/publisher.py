#!/usr/bin/env python
# coding=utf-8

# @file ieeexplore.py
# @brief ieeexplore
# @author x565178035,x565178035@126.com
# @version 1.0
# @date 2017-12-12 10:13
import requests
import json
import re
from lxml import etree

ieee_url = 'http://ieeexplore.ieee.org'
acm_url='https://dl.acm.org'
springer_url='https://link.springer.com'
elsevier_url='http://www.sciencedirect.com'
semanticsholar_url='https://www.semanticscholar.org'

proxies_ssr = {
    "http": "http://127.0.0.1:1080",
    "https": "http://127.0.0.1:1080"}
proxies_burp = {
    "http": "http://127.0.0.1:8080",
    "https": "http://127.0.0.1:8080"}
proxies=None

USER_AGENT='Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/62.0.3202.94 Safari/537.36'


def ieeexplore_find(title):
    '''
    输入：论文标题
    输出；论文url or None
    '''
    headers = {
        'User-Agent': USER_AGENT,
        'Referer':'http://ieeexplore.ieee.org/search/searchresult.jsp',
        'Content-Type':'application/json;charset=UTF-8'
    }

    cookies = {'visitstart': '11:17'}
    query = {'queryText': title, "newsearch": "true"}
    res = requests.post(
        ieee_url + '/rest/search',
        headers=headers,
        cookies=cookies,
        data=json.dumps(query),
        proxies=proxies)
    paper=json.loads(res.text)['records']
    if len(paper)==0:
        return None
    paper=paper[0]
    if paper['title'].replace('[::','').replace('::]','')==title:
        return ieee_url+paper['documentLink']

def ieeexplore_paper(url):
    headers = {'User-Agent': USER_AGENT}
    cookies = {'visitstart': '11:17'}
    res = requests.get(url,
        headers=headers,
        cookies=cookies,
        proxies=proxies)
    pattern = re.compile(ur'metadata={.*};')
    res=json.loads(pattern.search(res.text).group()[9:-1])
    paper=dict(
            title=res['title'],
            published_in=res['displayPublicationTitle'],
            doi=res['doi'],
            keywords=','.join(res['keywords'][0]["kwd"]),
            abstract=res['abstract']
            )
    return paper

def acm_find(title):
    '''
    输入：论文标题
    输出；论文url or None
    '''

    headers = {'User-Agent': USER_AGENT}
    query = {'query': title}
    res = requests.get(acm_url+'/results.cfm',
            headers=headers,
            proxies=proxies_ssr,
            verify=False,
            params=query)
    selector=etree.HTML(res.text)
    href=selector.xpath('//a[contains(text(),"{}")]/@href'.format(title))
    if len(href)>0:
        return acm_url+'/'+href[0]
    else:
        return None

def acm_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url+'&preflayout=flat',
            headers=headers,
            proxies=proxies_ssr,
            verify=False)
    selector=etree.HTML(res.text)
    published_in=selector\
            .xpath("//td[contains(text(),'Published in:')]/../following-sibling::tr[3]")[0]\
            .xpath("string(.)")\
            .strip()

    doi=selector.xpath('//a[contains(@href,"doi")]/text()')[0]

    keywords=selector\
            .xpath("//div[contains(@id,'authortags')]")[0]\
            .xpath("string(.)")\
            .replace('\r','')\
            .strip()\
            .split('\n')
    keywords=filter(lambda e:e!="",keywords)
    keywords=','.join(keywords)

    abstract=selector\
            .xpath("//div[contains(@class,'flatbody')]/div/p")[0]\
            .xpath("string(.)")
    paper=dict(
            published_in=published_in,
            doi=doi,
            keywords=keywords,
            abstract=abstract)
    return paper

def springer_find(title):
    headers = {'User-Agent': USER_AGENT}
    query = {'query': title}
    res = requests.get(springer_url+'/search',
            headers=headers,
            verify=False,
            params=query)
    selector=etree.HTML(res.text)
    href=selector.xpath('//a[contains(text(),"{}")]/@href'.format(title))
    if len(href)>0:
        return springer_url+href[0]
    else:
        return None

def springer_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers,
            verify=False)
    selector=etree.HTML(res.text)
    published_in=selector.xpath('//span[contains(@class,"JournalTitle")]/text()')[0]
    doi=selector.xpath('//span[contains(@id,"doi-url")]/text()')[0]
    doi='/'.join(doi.split('/')[-2:])
    abstract=selector.xpath('//section[contains(@class,"Abstract")]/p')[0]\
            .xpath("string(.)")
    keywords=selector.xpath('//span[contains(@class,"Keyword")]/text()')
    keywords=map(lambda e:e[:-1],keywords)
    keywords=','.join(keywords)
    paper=dict(
            published_in=published_in,
            doi=doi,
            keywords=keywords,
            abstract=abstract)
    return paper

def arxiv_paper(url):
    '''
    arxiv很特殊的收录，只有摘要
    '''
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers,
            verify=False)
    selector=etree.HTML(res.text.encode('utf8'))
    abstract=selector.xpath('//blockquote[contains(@class,"abstract")]/text()')[1].strip()
    paper=dict(
            published_in='arXiv',
            doi='',
            keywords='',
            abstract=abstract)
    return paper

def elsevier_find(title):
    headers = {'User-Agent': USER_AGENT}
    query = {'qs': title}
    res = requests.get(elsevier_url+'/search',
            headers=headers,
            params=query)
    selector=etree.HTML(res.text)
    search_title=selector.xpath('//div[contains(@class,"result-item-content")]/h2')[0]\
            .xpath('string(.)')
    if search_title==title:
        href=selector.xpath('//div[contains(@class,"result-item-content")]/h2/a/@href')[0]
        return elsevier_url+href
    else:
        return None

def elsevier_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers)
    selector=etree.HTML(res.text.encode('utf8'))
    published_in=selector.xpath('//a[contains(@class,"publication-title-link")]/text()')[0]

    doi=selector.xpath('//a[contains(@class,"doi")]/text()')[0]
    doi='/'.join(doi.split('/')[-2:])

    abstract=selector.xpath('//div[contains(@class,"abstract author")]/div')[0]\
            .xpath('string(.)')

    keywords=selector.xpath('//div[contains(@class,"Keywords")]/div/div')
    keywords=map(lambda e:e.xpath('string(.)'),keywords)
    keywords=",".join(keywords)
    paper=dict(
            published_in=published_in,
            doi=doi,
            keywords=keywords,
            abstract=abstract)
    return paper

def wiley_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers)
    selector=etree.HTML(res.text.encode('utf8'))
    published_in=selector.xpath('//img[contains(@class,"journal-header__logo-img")]/@alt')[0]

    doi=selector.xpath('//span[contains(@class,"article-header__meta-info-data")]/text()')[0]
    doi='/'.join(doi.split('/')[-2:])

    abstract=selector.xpath('//div[contains(@class,"mainAbstract")]/p')[0]\
            .xpath('string(.)')

    paper=dict(
            published_in=published_in,
            doi=doi,
            keywords="",
            abstract=abstract)
    return paper

def semanticsholar_find(title):
    headers = {'User-Agent': USER_AGENT,
            'Content-Type':'application/json'}
    query='{"queryString":"'+title+'","page":1,"pageSize":1000,"sort":"relevance","authors":[],"coAuthors":[],"venues":[],"facets":{},"yearFilter":null,"enableEntities":true,"enableRefinements":true,"requireViewablePdf":false,"publicationTypes":[],"disableFacetAggregations":true,"entities":[]}'

    res = requests.post(semanticsholar_url+'/api/1/search',
            headers=headers,
            data=query,
            verify=False)
    res=json.loads(res.text.encode('utf8'))
    res=res["results"]
    papers=filter(lambda e:e['title']['text']==title,res)
    if len(papers)==0:
        return None
    else:
        paper=papers[0]
        return semanticsholar_url+'/paper/'+paper['slug']+'/'+paper['id']

def semanticsholar_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers,
            verify=False)
    selector=etree.HTML(res.text)
    selector=etree.HTML(res.text.encode('utf8'))
    title=selector.xpath('//h1[contains(@data-selenium-selector,"paper-detail-title")]/text()')[0]
    print title

    headers = {'User-Agent': USER_AGENT,
            'Content-Type':'application/json'}
    query='{"queryString":"'+title+'","page":1,"pageSize":1000,"sort":"relevance","authors":[],"coAuthors":[],"venues":[],"facets":{},"yearFilter":null,"enableEntities":true,"enableRefinements":true,"requireViewablePdf":false,"publicationTypes":[],"disableFacetAggregations":true,"entities":[]}'

    res = requests.post(semanticsholar_url+'/api/1/search',
            headers=headers,
            data=query,
            verify=False)
    res=json.loads(res.text.encode('utf8'))
    res=res["results"]
    paper=filter(lambda e:e['title']['text']==title,res)[0]

    keywords=selector.xpath('//div[contains(@class,"Keywords")]/div/div')
    keywords=map(lambda e:e.xpath('string(.)'),keywords)
    keywords=",".join(keywords)
    paper=dict(
            published_in=paper["venue"]["text"],
            doi="",
            keywords=",".join(paper["keyPhrases"]),
            abstract=paper["paperAbstract"]["text"])
    return paper

def inderscience_paper(url):
    headers = {'User-Agent': USER_AGENT}
    res = requests.get(url,
            headers=headers)
    selector=etree.HTML(res.text.encode('utf8'))
    published_in=selector.xpath('//div[contains(@class,"page-heading")]/h1/text()')[0]

    doi=selector.xpath('//a[contains(@href,"doi.org")]/text()')[0]
    doi='/'.join(doi.split('/')[-2:])

    abstract=selector.xpath('//div[contains(@class,"abstractSection")]/p')[0]\
            .xpath('string(.)')

    keywords=selector.xpath('//div[contains(@class,"hlFld-KeywordText")]/kwd-group/a')
    keywords=map(lambda e:e.xpath('string(.)'),keywords)
    keywords=",".join(keywords)
    paper=dict(
            published_in=published_in,
            doi=doi,
            keywords=keywords,
            abstract=abstract)
    return paper


if __name__ == '__main__':
    #  print ieeexplore_find(
        #  'A Taxonomy and Qualitative Comparison of Program Analysis Techniques for Security Assessment of Android Software')
    #  ieeexplore_paper('http://ieeexplore.ieee.org/document/7583740/')
    #  print acm_find('Unleashing the Walking Dead: Understanding Cross-App Remote Infections on Mobile WebViews')
    #  print acm_paper('https://dl.acm.org/citation.cfm?id=3134021&CFID=839575348&CFTOKEN=53726605')
    #  print springer_find('Detecting plagiarized mobile apps using API birthmarks')
    #  print springer_paper('https://link.springer.com/article/10.1007/s10515-015-0182-6')
    #  print arxiv_paper('https://arxiv.org/abs/1604.06964')

    #  print elsevier_find("Fingerprinting Android packaging: Generating DNAs for malware detection")
    #  print elsevier_paper("http://www.sciencedirect.com/science/article/pii/S1742287616300469")

    #  print wiley_paper("http://onlinelibrary.wiley.com/doi/10.1002/ett.3016/full")

    #  print semanticsholar_find("IntelliDroid: A Targeted Input Generator for the Dynamic Analysis of Android Malware")
    #  print semanticsholar_paper("https://www.semanticscholar.org/paper/IntelliDroid-A-Targeted-Input-Generator-for-the-Dy-Wong-Lie/17138b471f2dade960cd3969db0c08b623b33797")
    print inderscience_paper('https://www.inderscienceonline.com/doi/abs/10.1504/IJSN.2016.075073')
