#!/usr/bin/env python
#coding=utf-8

# @file compete_paper.py
# @brief compete_paper
# @author x565178035,x565178035@126.com
# @version 1.0
# @date 2017-12-14 10:15

import traceback
import publisher
import re
import requests
from multiprocessing import Pool #多线程用
from contextlib import closing
# Django specific settings
import os
os.environ.setdefault("DJANGO_SETTINGS_MODULE", "settings")
import django
django.setup()

# Import your models for use in your script
from db.models import *

finders={
        "ieeexplore.ieee.org":publisher.ieeexplore_find,
        "dl.acm.org":publisher.acm_find,
        "pdfs.semanticscholar.org":publisher.semanticsholar_find,
        "Springer":publisher.springer_find,
        "Elsevier":publisher.elsevier_find,
        }
paper_extractors={
        "ieeexplore.ieee.org":publisher.ieeexplore_paper,
        "dl.acm.org":publisher.acm_paper,
        "Springer":publisher.springer_paper,
        "arxiv.org":publisher.arxiv_paper,
        "Elsevier":publisher.elsevier_paper,
        "WileyOnlineLibrary":publisher.wiley_paper,
        "pdfs.semanticscholar.org":publisher.semanticsholar_paper,
        "inderscienceonline.com":publisher.inderscience_paper,
        }

en_pattern = re.compile(u'^[a-zA-Z].*')
def is_en(word):
    '''
    判断传入字符串是否包含中文
    :param word: 待判断字符串
    :return: True:包含中文  False:不包含中文
    '''
    word = word.decode()
    match = en_pattern.search(word)

    return match
def compete_single(paper):
    try:
        print 'processing:',paper.id
        paper_dict=None
        if paper.published_in!=None or paper.published_in=='arXiv' or paper.include=='GooglePatents':
            return
        if (not paper.inc_url.endswith('pdf') ) and paper.include in paper_extractors.keys():
            paper_dict=paper_extractors[paper.include](paper.inc_url)
        elif not is_en(paper.title):
            pass
        else:
            for id,finder in finders.iteritems():
                title=paper.title[:-1] if paper.title[-1]=='.' else paper.title
                url=finder(title)
                if url!=None:
                    paper_dict=paper_extractors[id](url)
                    paper_dict["inc_url"]=url
                    paper_dict["include"]=id
                    break
        '''
        修改情况 'published_in': u'Big Data (Big Data), 2016 IEEE International Conference on'
        '''
        if paper_dict!=None:
            if paper_dict["published_in"].endswith(' on'):
                published_in=paper_dict["published_in"]
                published_in=published_in.split(",")
                published_in=published_in[1].strip()+" "+published_in[0].strip()
                paper_dict["published_in"]=published_in
        if paper_dict!=None:
            paper.published_in=paper_dict['published_in'].strip() if len(paper_dict['published_in']) else None
            paper.doi=paper_dict['doi'] if len(paper_dict['doi']) else None
            paper.keywords=paper_dict['keywords'] if len(paper_dict['keywords']) else None
            paper.abstract=paper_dict['abstract'] if len(paper_dict['abstract']) else None
            if paper_dict.has_key("include"):
                paper.inc_url=paper_dict["inc_url"]
                paper.include=paper_dict["include"]
        else:
            paper.published_in='NotFound'
        paper.save()
    except UnicodeEncodeError:
        pass
    #  except requests.exceptions.ChunkedEncodingError:
        #  pass
    except Exception:
        print paper.id
        traceback.print_exc()
        #  raw_input()

def compete_paper():

    with closing(Pool(processes=5)) as p:
        p.map(compete_single, Paper.objects.all())
    #  for each in Paper.objects.filter(include="usenix.org"):
        #  compete_single(each)

if __name__ == '__main__':
    compete_paper()
    #  compete_single(Paper.objects.get(id=770))

